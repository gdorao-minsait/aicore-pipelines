apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: case1-serving-pipeline # executable ID, must be unique across your SAP AI Core instance, for example use `server-pipeline-yourname-1234`
  annotations:
    scenarios.ai.sap.com/name: "Case1 Bottle Detection Scenario" # Scenario name should be the use case
    scenarios.ai.sap.com/description: "Image detection with bottles of Estrella Galicia"

    executables.ai.sap.com/name: "case1-model-serving" # Executable name should describe the workflow in the use case  
    executables.ai.sap.com/description: "Serving CV model with Estrella Galicia dataset"

  labels:
    scenarios.ai.sap.com/id: "case1-detection-scenario"
    ai.sap.com/version: "0.2"
spec:
  template:
    apiVersion: "serving.kserve.io/v1beta1"
    metadata:
      annotations: |
        autoscaling.knative.dev/metric: concurrency   # condition when to scale
        autoscaling.knative.dev/target: 1
        autoscaling.knative.dev/targetBurstCapacity: 0
      labels: |
        ai.sap.com/resourcePlan: starter # computing power
    spec: |
      predictor:
        imagePullSecrets:
          - name: case1
        minReplicas: 1
        maxReplicas: 5    # how much to scale
        containers:
        - name: kserve-container
          image: docker.io/gdoraominsait/vessel_visionaries_serve:0.1
          ports:
            - containerPort: 9001    # customizable port
              protocol: TCP
          command: ["/bin/sh", "-c", "python /app/src/main.py"]